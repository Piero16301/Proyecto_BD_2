# Proyecto 2 Base de Datos
Recuperaci贸n de documentos de texto

## Res煤men
Este proyecto consiste en la aplicaci贸n de los algoritmos de b煤squeda y recuperaci贸n de la informaci贸n basada en el contenido. Este proyecto est谩 enfocado a la construcci贸n 贸ptima del ndice Invertido para tareas de b煤squeda y recuperaci贸n en documentos de texto.

## Backend
En el proyecto se ha implementado el 铆nidice invertido para la recuperaci贸n de texto usando el modelo de recuperaci贸n por ranking para consultas de texto libre, considerando las siguientes etapas generales.

1. Preprocesamiento
   * Tokenizaci贸n
   * Filtrado de stopwords
   * Reducci贸n de palabras mediante Stemming
   
2. Construcci贸n del 铆ndice
   * Estructurar el 铆ndice para obtener los pesos TF-IDF
   * Manejo del 铆ndice en memoria secundaria para soportar grandes cantidades de datos.
      + Uso de Blocked Sort-Based Indexing
 
3. Consultas
   * La consulta est谩 formada por una o m谩s palabras en lenguaje natural.
   * El puntaje (score) obtenido est谩 basado en la similitud de coseno y retorna una lista ordenada de documentos que se aproximan a la consulta.
   
## Frontend
Para probar el desempe帽o del 铆ndice invertido, se ha construido una aplicaci贸n frontend que permite interactuar con las principales operaciones del 铆ndice invertido, que son las siguientes.
* Carga e indexaci贸n de los documentos en tiempo real
* B煤squeda textual relacionada a los temas de inter茅s
* Presentaci贸n de los resultados de forma amigable e intuitiva.

## Implementaci贸n
### Backend
#### Preprocesamiento
Primero se extraen los nombres de los archivos json que se encuentran en el directorio que se quiere evaluar, y se guarda en una lista.
```
listaArchivos = os.listdir(dirName)
```
Luego se procede a guardar los stopwords que se encuentran en un archivo de texto plano, y se guardan en una lista para hacer el filtrado del contenido de los archivos json m谩s adelante.
```
stopwords = list()
stopFile = codecs.open("stoplist.txt", "r", "utf-8")
    for line in stopFile:
        line = line.strip()
        line = line.lower()
        words = line.split(" ")
        for word in words:
            if word not in stopwords:
                stopwords.append(word)
```
Finalmente, se realiza una iteraci贸n sobre cada uno de los archivos json. Para cada archivo, se itera sobre cada uno de sus elementos, que vendr铆an a ser los tweets, se hace la separaci贸n en palabras del atributo RT_text o text dependiendo si es retweet o no, para obtener el texto original. Luego se hace la eliminaci贸n de los caracteres especiales y la transformaci贸n de todas las letras a min煤scula. Despu茅s, se hace el filtrado de los stopwords y las direcciones url y se guarda temporalmente en una lista que va a contener las palabras filtradas de ese tweet. Finalmente, se realiza el proceso de Stemming y se agregan las palabras resultantes a la lista de tokens totales, se eliminan las palabras duplicadas y se retorna la lista de tokens totales.
```
for archivo in listaArchivos:
    for tweet in tweets:
        if tweet['retweeted'] is True:
            texto = tweet['RT_text']
        else:
            texto = tweet['text']
        texto = texto.strip()
        texto = re.sub('[驴|?|$|.|,|:|;|!|潞|芦|禄|(|)|@|隆|"|||/|#|%]', '', texto)
        texto = texto.lower()
        for token in tokens:
            if token in stopwords:
                continue
            if "http" in token:
                continue
            keywords.append(token)
        stemmer = SnowballStemmer('spanish')
        for token in keywords:
            tokensTotales.append(stemmer.stem(token))
    tokensTotales = list(dict.fromkeys(tokensTotales))
return tokensTotales
```

### Frontend

## Testing
Para realizar las pruebas del 铆ndice, se han cargado 25 archivos en formato json con un total 32 831 tweets y un tama帽o de 15 MB que van a ser analizados durante la consulta. Para poder realizar la consulta, se debe ejecutar el servidor de flask que se encuentra en el archivo front.py el cual muestra la siguiente ventana de b煤squeda en el navegador.

![](images/home_page.png)

En esta ventana se procede a realizar una consulta que puede contener una o m谩s palabras de lenguaje natural y que pueden estar relacionadas o con el tema de los tweets que son sobre los candidatos a la alcald铆a de Lima. Los resultados se muestran de la siguiente manera.

![](images/resultado_consulta.png)

En esta parte se muestran los 'k' tweets con mayor puntaje en relaci贸n a la consulta. Y si el usuario lo desea, puede hacer click en el bot贸n 'Ver tweet +' en la columna 'Detalles' para visualizar el contenido del tweet correspondiente a ese ID de tweet. Por ejemplo, en la consulta hecha anteriormente 'renzo keiko comunicore', al mostrar los detalles del tweet con mayor puntaje de 0.9318 se muestra el siguiente contenido.

![](images/vista_tweet.png)
